{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b673f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NERVA Quantum FX Dynamics Engine - ALPHA CLEARANCE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class QuantumFXEngine:\n",
    "    def __init__(self):\n",
    "        self.fx_models = {}\n",
    "        self.volatility_models = {}\n",
    "        self.intervention_detector = None\n",
    "        \n",
    "        # Professional color scheme\n",
    "        self.colors = {\n",
    "            'primary': '#1f77b4',\n",
    "            'secondary': '#ff7f0e', \n",
    "            'success': '#2ca02c',\n",
    "            'warning': '#d62728',\n",
    "            'info': '#9467bd'\n",
    "        }\n",
    "        \n",
    "        pio.templates.default = 'plotly_white'\n",
    "    \n",
    "    def load_fx_data(self):\n",
    "        \"\"\"Load and prepare FX data\"\"\"\n",
    "        # Create synthetic FX data for demonstration\n",
    "        np.random.seed(42)\n",
    "        dates = pd.date_range('2020-01-01', periods=1000, freq='D')\n",
    "        \n",
    "        # USD/KES with realistic dynamics\n",
    "        base_rate = 110\n",
    "        trend = np.cumsum(np.random.normal(0, 0.5, 1000)) * 0.1\n",
    "        volatility = np.abs(np.sin(np.arange(1000) * 0.02)) * 2 + 1\n",
    "        noise = np.random.normal(0, 1, 1000) * volatility\n",
    "        \n",
    "        usd_kes = base_rate + trend + noise\n",
    "        \n",
    "        # Other currency pairs\n",
    "        eur_kes = usd_kes * (1.1 + np.random.normal(0, 0.05, 1000))\n",
    "        gbp_kes = usd_kes * (1.25 + np.random.normal(0, 0.03, 1000))\n",
    "        \n",
    "        fx_data = pd.DataFrame({\n",
    "            'date': dates,\n",
    "            'USD_KES': usd_kes,\n",
    "            'EUR_KES': eur_kes,\n",
    "            'GBP_KES': gbp_kes,\n",
    "            'volatility': volatility\n",
    "        })\n",
    "        \n",
    "        # Add technical indicators\n",
    "        for pair in ['USD_KES', 'EUR_KES', 'GBP_KES']:\n",
    "            fx_data[f'{pair}_return'] = fx_data[pair].pct_change()\n",
    "            fx_data[f'{pair}_sma_20'] = fx_data[pair].rolling(20).mean()\n",
    "            fx_data[f'{pair}_volatility'] = fx_data[f'{pair}_return'].rolling(20).std() * np.sqrt(252)\n",
    "        \n",
    "        print(\"FX Data loaded successfully\")\n",
    "        print(f\"Data shape: {fx_data.shape}\")\n",
    "        print(f\"Date range: {fx_data['date'].min()} to {fx_data['date'].max()}\")\n",
    "        \n",
    "        return fx_data\n",
    "    \n",
    "    def analyze_volatility_clustering(self, fx_data, pair='USD_KES'):\n",
    "        \"\"\"Analyze volatility clustering patterns\"\"\"\n",
    "        returns = fx_data[f'{pair}_return'].dropna()\n",
    "        \n",
    "        # Calculate ARCH effects\n",
    "        squared_returns = returns ** 2\n",
    "        autocorr = squared_returns.autocorr()\n",
    "        \n",
    "        # Volatility regimes\n",
    "        vol_high = returns.std() * 1.5\n",
    "        vol_low = returns.std() * 0.5\n",
    "        \n",
    "        high_vol_periods = np.abs(returns) > vol_high\n",
    "        low_vol_periods = np.abs(returns) < vol_low\n",
    "        \n",
    "        clustering_analysis = {\n",
    "            'autocorrelation': autocorr,\n",
    "            'high_vol_periods': high_vol_periods.sum(),\n",
    "            'low_vol_periods': low_vol_periods.sum(),\n",
    "            'volatility_persistence': squared_returns.rolling(30).mean().std()\n",
    "        }\n",
    "        \n",
    "        print(f\"Volatility Clustering Analysis for {pair}:\")\n",
    "        print(f\"  Autocorrelation: {autocorr:.4f}\")\n",
    "        print(f\"  High volatility periods: {high_vol_periods.sum()}\")\n",
    "        print(f\"  Volatility persistence: {clustering_analysis['volatility_persistence']:.4f}\")\n",
    "        \n",
    "        return clustering_analysis\n",
    "    \n",
    "    def detect_intervention_points(self, fx_data, pair='USD_KES', threshold=3):\n",
    "        \"\"\"Detect potential central bank intervention points\"\"\"\n",
    "        returns = fx_data[f'{pair}_return'].dropna()\n",
    "        \n",
    "        # Z-score based detection\n",
    "        z_scores = np.abs((returns - returns.mean()) / returns.std())\n",
    "        potential_interventions = z_scores > threshold\n",
    "        \n",
    "        # Rate of change acceleration\n",
    "        rate_change = fx_data[pair].diff().diff()\n",
    "        acceleration_threshold = rate_change.std() * 2\n",
    "        acceleration_events = np.abs(rate_change) > acceleration_threshold\n",
    "        \n",
    "        intervention_points = potential_interventions | acceleration_events\n",
    "        \n",
    "        print(f\"Intervention Detection for {pair}:\")\n",
    "        print(f\"  Potential intervention points: {intervention_points.sum()}\")\n",
    "        print(f\"  Percentage of observations: {intervention_points.mean()*100:.2f}%\")\n",
    "        \n",
    "        return intervention_points, z_scores\n",
    "    \n",
    "    def create_fx_dashboard(self, fx_data):\n",
    "        \"\"\"Create comprehensive FX analysis dashboard\"\"\"\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=3, cols=2,\n",
    "            subplot_titles=[\n",
    "                'USD/KES Exchange Rate', 'Cross-Currency Correlations',\n",
    "                'Volatility Analysis', 'Intervention Detection',\n",
    "                'Return Distributions', 'Technical Indicators'\n",
    "            ],\n",
    "            specs=[[{}, {}],\n",
    "                   [{}, {}],\n",
    "                   [{}, {}]]\n",
    "        )\n",
    "        \n",
    "        # 1. Main FX rate\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=fx_data['date'], \n",
    "                y=fx_data['USD_KES'],\n",
    "                mode='lines',\n",
    "                name='USD/KES',\n",
    "                line=dict(color=self.colors['primary'], width=2)\n",
    "            ), row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Add SMA\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=fx_data['date'],\n",
    "                y=fx_data['USD_KES_sma_20'],\n",
    "                mode='lines',\n",
    "                name='20-day SMA',\n",
    "                line=dict(color=self.colors['secondary'], dash='dash')\n",
    "            ), row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # 2. Cross-currency correlations (heatmap-style)\n",
    "        corr_data = fx_data[['USD_KES', 'EUR_KES', 'GBP_KES']].corr()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=corr_data.values,\n",
    "                x=corr_data.columns,\n",
    "                y=corr_data.columns,\n",
    "                colorscale='RdBu',\n",
    "                zmid=0,\n",
    "                showscale=False\n",
    "            ), row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # 3. Volatility time series\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=fx_data['date'],\n",
    "                y=fx_data['USD_KES_volatility'],\n",
    "                mode='lines',\n",
    "                name='Volatility',\n",
    "                line=dict(color=self.colors['warning'], width=2)\n",
    "            ), row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # 4. Intervention points\n",
    "        intervention_points, z_scores = self.detect_intervention_points(fx_data)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=fx_data['date'],\n",
    "                y=z_scores,\n",
    "                mode='lines',\n",
    "                name='Z-Scores',\n",
    "                line=dict(color=self.colors['info'])\n",
    "            ), row=2, col=2\n",
    "        )\n",
    "        \n",
    "        # Add intervention threshold\n",
    "        fig.add_hline(y=3, line_dash=\"dash\", line_color=\"red\", row=2, col=2)\n",
    "        fig.add_hline(y=-3, line_dash=\"dash\", line_color=\"red\", row=2, col=2)\n",
    "        \n",
    "        # 5. Return distribution\n",
    "        returns = fx_data['USD_KES_return'].dropna()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=returns,\n",
    "                nbinsx=50,\n",
    "                name='Return Distribution',\n",
    "                marker_color=self.colors['success'],\n",
    "                opacity=0.7\n",
    "            ), row=3, col=1\n",
    "        )\n",
    "        \n",
    "        # 6. Technical momentum\n",
    "        momentum = fx_data['USD_KES'] - fx_data['USD_KES_sma_20']\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=fx_data['date'],\n",
    "                y=momentum,\n",
    "                mode='lines',\n",
    "                name='Momentum',\n",
    "                line=dict(color=self.colors['primary'])\n",
    "            ), row=3, col=2\n",
    "        )\n",
    "        \n",
    "        fig.add_hline(y=0, line_dash=\"solid\", line_color=\"black\", row=3, col=2)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title_text=\"NERVA Quantum FX Dynamics Dashboard\",\n",
    "            height=1000,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# Initialize FX Engine\n",
    "fx_engine = QuantumFXEngine()\n",
    "\n",
    "# Load and analyze data\n",
    "fx_data = fx_engine.load_fx_data()\n",
    "\n",
    "print(\"NERVA Quantum FX Engine initialized successfully\")\n",
    "print(\"Advanced currency modeling protocols active\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform advanced volatility clustering analysis\n",
    "print(\"Performing volatility clustering analysis...\")\n",
    "\n",
    "# Analyze volatility clustering for major pairs\n",
    "usd_kes_clustering = fx_engine.analyze_volatility_clustering(fx_data, 'USD_KES')\n",
    "eur_kes_clustering = fx_engine.analyze_volatility_clustering(fx_data, 'EUR_KES')\n",
    "gbp_kes_clustering = fx_engine.analyze_volatility_clustering(fx_data, 'GBP_KES')\n",
    "\n",
    "# Create comprehensive dashboard\n",
    "print(\"Generating FX dynamics dashboard...\")\n",
    "fx_dashboard = fx_engine.create_fx_dashboard(fx_data)\n",
    "fx_dashboard.show()\n",
    "\n",
    "print(\"Volatility clustering analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6a1ce",
   "metadata": {},
   "source": [
    "# NERVA Quantum FX Dynamics Engine\n",
    "\n",
    "**Classification:** ALPHA - Authorized Personnel Only  \n",
    "**System:** National Economic & Risk Visual Analytics  \n",
    "**Module:** Foreign Exchange Quantum Modeling  \n",
    "**Clearance Level:** RESTRICTED\n",
    "\n",
    "---\n",
    "\n",
    "## Mission Objectives:\n",
    "- Advanced currency pair modeling with deep learning\n",
    "- Real-time volatility clustering analysis\n",
    "- Cross-currency correlation matrices\n",
    "- Intervention point detection algorithms\n",
    "- Market microstructure analysis\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
