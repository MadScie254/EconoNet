{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3bac01",
   "metadata": {},
   "source": [
    "# Risk Analysis Notebook\n",
    "## Monte Carlo Simulation, VaR, and CVaR Analysis\n",
    "\n",
    "This notebook provides comprehensive risk analysis tools for financial and economic data:\n",
    "- **Value at Risk (VaR)**: Maximum expected loss at a given confidence level\n",
    "- **Conditional Value at Risk (CVaR)**: Expected loss beyond VaR threshold\n",
    "- **Monte Carlo Simulation**: Probabilistic scenario generation\n",
    "- **Stress Testing**: Impact analysis under extreme conditions\n",
    "\n",
    "### Key Features:\n",
    "- Multiple VaR calculation methods (Historical, Parametric, Monte Carlo)\n",
    "- Advanced Monte Carlo simulations with various distributions\n",
    "- Portfolio risk metrics and optimization\n",
    "- Stress testing scenarios and backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509184e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üìö Libraries imported successfully\")\n",
    "print(\"üéØ Random seed set for reproducible results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom risk models\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "try:\n",
    "    from models.risk import VaRCalculator, MonteCarloSimulator, StressTesting\n",
    "    from utils.plotting import ECONET_COLORS\n",
    "    print(\"‚úÖ Custom risk models imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Import warning: {e}\")\n",
    "    print(\"üìù Using fallback implementations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a62cc",
   "metadata": {},
   "source": [
    "## 1. Data Generation and Preparation\n",
    "\n",
    "Generate synthetic financial returns data with realistic characteristics:\n",
    "- Fat tails (higher probability of extreme events)\n",
    "- Volatility clustering\n",
    "- Autocorrelation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e415f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (can be overridden by Streamlit)\n",
    "var_confidence = 0.95\n",
    "n_simulations = 1000\n",
    "\n",
    "def generate_financial_returns(n_periods=252, assets=['Stock', 'Bond', 'Commodity']):\n",
    "    \"\"\"\n",
    "    Generate synthetic financial returns with realistic properties\n",
    "    \"\"\"\n",
    "    dates = pd.date_range('2020-01-01', periods=n_periods, freq='D')\n",
    "    \n",
    "    returns_data = {}\n",
    "    \n",
    "    for i, asset in enumerate(assets):\n",
    "        # Base parameters\n",
    "        mu = [0.0005, 0.0002, 0.0003][i]  # Daily expected returns\n",
    "        base_vol = [0.02, 0.008, 0.025][i]  # Base volatility\n",
    "        \n",
    "        # Generate returns with volatility clustering (GARCH-like)\n",
    "        returns = []\n",
    "        vol = base_vol\n",
    "        \n",
    "        for t in range(n_periods):\n",
    "            # Volatility update (simplified GARCH)\n",
    "            if t > 0:\n",
    "                vol = 0.8 * vol + 0.1 * base_vol + 0.1 * abs(returns[-1])\n",
    "            \n",
    "            # Generate return with fat tails (t-distribution)\n",
    "            if np.random.random() < 0.05:  # 5% chance of extreme event\n",
    "                ret = stats.t.rvs(df=3, scale=vol * 2) + mu\n",
    "            else:\n",
    "                ret = np.random.normal(mu, vol)\n",
    "            \n",
    "            returns.append(ret)\n",
    "        \n",
    "        returns_data[asset] = returns\n",
    "    \n",
    "    # Add some correlation\n",
    "    corr_matrix = np.array([\n",
    "        [1.0, 0.3, 0.5],\n",
    "        [0.3, 1.0, 0.2],\n",
    "        [0.5, 0.2, 1.0]\n",
    "    ])\n",
    "    \n",
    "    # Apply correlation (simplified)\n",
    "    returns_matrix = np.array(list(returns_data.values())).T\n",
    "    \n",
    "    df = pd.DataFrame(returns_matrix, columns=assets, index=dates)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate returns data\n",
    "returns_data = generate_financial_returns()\n",
    "print(f\"üìä Generated {len(returns_data)} days of returns data\")\n",
    "print(f\"üíº Assets: {list(returns_data.columns)}\")\n",
    "print(f\"üìà Date range: {returns_data.index[0].strftime('%Y-%m-%d')} to {returns_data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nüìä Returns Summary Statistics:\")\n",
    "summary_stats = returns_data.describe()\n",
    "print(summary_stats.round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbf0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize returns data\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['Cumulative Returns', 'Daily Returns Distribution', \n",
    "                   'Rolling Volatility (30-day)', 'Returns Correlation'],\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"type\": \"heatmap\"}]]\n",
    ")\n",
    "\n",
    "# 1. Cumulative returns\n",
    "cumulative_returns = (1 + returns_data).cumprod()\n",
    "for col in returns_data.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=returns_data.index, y=cumulative_returns[col], \n",
    "                  name=f'{col} Cumulative', mode='lines'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# 2. Returns distribution (histogram)\n",
    "for col in returns_data.columns:\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=returns_data[col], name=f'{col} Distribution', \n",
    "                    opacity=0.7, nbinsx=50),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# 3. Rolling volatility\n",
    "rolling_vol = returns_data.rolling(30).std() * np.sqrt(252)  # Annualized\n",
    "for col in returns_data.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=returns_data.index, y=rolling_vol[col], \n",
    "                  name=f'{col} Volatility', mode='lines'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# 4. Correlation heatmap\n",
    "corr_matrix = returns_data.corr()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(z=corr_matrix.values, \n",
    "               x=corr_matrix.columns, \n",
    "               y=corr_matrix.columns,\n",
    "               colorscale='RdBu',\n",
    "               zmid=0,\n",
    "               showscale=True),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='üìà Financial Returns Analysis',\n",
    "    height=800,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "print(\"üìà Returns data visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9d012",
   "metadata": {},
   "source": [
    "## 2. Value at Risk (VaR) Analysis\n",
    "\n",
    "Calculate VaR using multiple methodologies and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaR Calculation Functions\n",
    "class RiskCalculator:\n",
    "    def __init__(self, confidence_level=0.95):\n",
    "        self.confidence_level = confidence_level\n",
    "        self.alpha = 1 - confidence_level\n",
    "    \n",
    "    def historical_var(self, returns):\n",
    "        \"\"\"Calculate VaR using historical method\"\"\"\n",
    "        return np.percentile(returns, self.alpha * 100)\n",
    "    \n",
    "    def parametric_var(self, returns):\n",
    "        \"\"\"Calculate VaR using parametric method (normal distribution)\"\"\"\n",
    "        mu = np.mean(returns)\n",
    "        sigma = np.std(returns)\n",
    "        return stats.norm.ppf(self.alpha, mu, sigma)\n",
    "    \n",
    "    def monte_carlo_var(self, returns, n_simulations=10000):\n",
    "        \"\"\"Calculate VaR using Monte Carlo simulation\"\"\"\n",
    "        # Fit distribution to returns\n",
    "        mu = np.mean(returns)\n",
    "        sigma = np.std(returns)\n",
    "        \n",
    "        # Generate simulations\n",
    "        simulated_returns = np.random.normal(mu, sigma, n_simulations)\n",
    "        \n",
    "        return np.percentile(simulated_returns, self.alpha * 100)\n",
    "    \n",
    "    def conditional_var(self, returns, var_value):\n",
    "        \"\"\"Calculate Conditional VaR (Expected Shortfall)\"\"\"\n",
    "        tail_losses = returns[returns <= var_value]\n",
    "        return np.mean(tail_losses) if len(tail_losses) > 0 else var_value\n",
    "    \n",
    "    def calculate_all_metrics(self, returns):\n",
    "        \"\"\"Calculate comprehensive risk metrics\"\"\"\n",
    "        # VaR calculations\n",
    "        hist_var = self.historical_var(returns)\n",
    "        param_var = self.parametric_var(returns)\n",
    "        mc_var = self.monte_carlo_var(returns, n_simulations)\n",
    "        \n",
    "        # CVaR calculations\n",
    "        hist_cvar = self.conditional_var(returns, hist_var)\n",
    "        param_cvar = self.conditional_var(returns, param_var)\n",
    "        mc_cvar = self.conditional_var(returns, mc_var)\n",
    "        \n",
    "        # Additional metrics\n",
    "        volatility = np.std(returns) * np.sqrt(252)  # Annualized\n",
    "        skewness = stats.skew(returns)\n",
    "        kurtosis = stats.kurtosis(returns)\n",
    "        sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252)\n",
    "        \n",
    "        return {\n",
    "            'Historical_VaR': hist_var,\n",
    "            'Parametric_VaR': param_var,\n",
    "            'MonteCarlo_VaR': mc_var,\n",
    "            'Historical_CVaR': hist_cvar,\n",
    "            'Parametric_CVaR': param_cvar,\n",
    "            'MonteCarlo_CVaR': mc_cvar,\n",
    "            'Volatility': volatility,\n",
    "            'Skewness': skewness,\n",
    "            'Kurtosis': kurtosis,\n",
    "            'Sharpe_Ratio': sharpe_ratio\n",
    "        }\n",
    "\n",
    "# Calculate risk metrics for each asset\n",
    "risk_calculator = RiskCalculator(confidence_level=var_confidence)\n",
    "risk_metrics = {}\n",
    "\n",
    "print(f\"‚ö° Calculating risk metrics at {var_confidence*100}% confidence level...\")\n",
    "\n",
    "for asset in returns_data.columns:\n",
    "    returns = returns_data[asset].dropna()\n",
    "    metrics = risk_calculator.calculate_all_metrics(returns)\n",
    "    risk_metrics[asset] = metrics\n",
    "    \n",
    "    print(f\"\\nüìä {asset} Risk Metrics:\")\n",
    "    print(f\"  VaR (Historical): {metrics['Historical_VaR']:.4f}\")\n",
    "    print(f\"  VaR (Parametric): {metrics['Parametric_VaR']:.4f}\")\n",
    "    print(f\"  CVaR (Historical): {metrics['Historical_CVaR']:.4f}\")\n",
    "    print(f\"  Volatility (Ann.): {metrics['Volatility']:.2f}%\")\n",
    "    print(f\"  Sharpe Ratio: {metrics['Sharpe_Ratio']:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Risk metrics calculation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a41fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive risk metrics DataFrame\n",
    "risk_df = pd.DataFrame(risk_metrics).T\n",
    "\n",
    "print(\"üìä COMPREHENSIVE RISK METRICS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(risk_df.round(6))\n",
    "\n",
    "# Identify highest and lowest risk assets\n",
    "highest_risk = risk_df['Volatility'].idxmax()\n",
    "lowest_risk = risk_df['Volatility'].idxmin()\n",
    "best_sharpe = risk_df['Sharpe_Ratio'].idxmax()\n",
    "\n",
    "print(f\"\\nüéØ RISK INSIGHTS:\")\n",
    "print(f\"üìà Highest Risk Asset: {highest_risk} (Vol: {risk_df.loc[highest_risk, 'Volatility']:.2f}%)\")\n",
    "print(f\"üìâ Lowest Risk Asset: {lowest_risk} (Vol: {risk_df.loc[lowest_risk, 'Volatility']:.2f}%)\")\n",
    "print(f\"üèÜ Best Risk-Adjusted Return: {best_sharpe} (Sharpe: {risk_df.loc[best_sharpe, 'Sharpe_Ratio']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049797d6",
   "metadata": {},
   "source": [
    "## 3. Monte Carlo Simulation\n",
    "\n",
    "Perform Monte Carlo simulations to generate potential future scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Simulation for Portfolio Scenarios\n",
    "class MonteCarloRiskSimulator:\n",
    "    def __init__(self, n_simulations=1000, time_horizon=30):\n",
    "        self.n_simulations = n_simulations\n",
    "        self.time_horizon = time_horizon\n",
    "    \n",
    "    def geometric_brownian_motion(self, S0, mu, sigma, corr_matrix=None):\n",
    "        \"\"\"\n",
    "        Simulate asset prices using Geometric Brownian Motion\n",
    "        \"\"\"\n",
    "        if isinstance(S0, (int, float)):\n",
    "            # Single asset simulation\n",
    "            dt = 1/252  # Daily steps\n",
    "            \n",
    "            # Generate random shocks\n",
    "            Z = np.random.standard_normal((self.n_simulations, self.time_horizon))\n",
    "            \n",
    "            # Initialize price paths\n",
    "            S = np.zeros((self.n_simulations, self.time_horizon + 1))\n",
    "            S[:, 0] = S0\n",
    "            \n",
    "            # Generate paths\n",
    "            for t in range(1, self.time_horizon + 1):\n",
    "                S[:, t] = S[:, t-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * Z[:, t-1])\n",
    "            \n",
    "            return S\n",
    "        \n",
    "        else:\n",
    "            # Multi-asset simulation\n",
    "            n_assets = len(S0)\n",
    "            dt = 1/252\n",
    "            \n",
    "            # Generate correlated random shocks\n",
    "            if corr_matrix is not None:\n",
    "                L = np.linalg.cholesky(corr_matrix)\n",
    "                Z = np.random.standard_normal((self.n_simulations, self.time_horizon, n_assets))\n",
    "                Z = np.array([np.dot(z, L.T) for z in Z])\n",
    "            else:\n",
    "                Z = np.random.standard_normal((self.n_simulations, self.time_horizon, n_assets))\n",
    "            \n",
    "            # Initialize price paths\n",
    "            S = np.zeros((self.n_simulations, self.time_horizon + 1, n_assets))\n",
    "            S[:, 0, :] = S0\n",
    "            \n",
    "            # Generate paths\n",
    "            for t in range(1, self.time_horizon + 1):\n",
    "                for i in range(n_assets):\n",
    "                    S[:, t, i] = S[:, t-1, i] * np.exp(\n",
    "                        (mu[i] - 0.5 * sigma[i]**2) * dt + sigma[i] * np.sqrt(dt) * Z[:, t-1, i]\n",
    "                    )\n",
    "            \n",
    "            return S\n",
    "    \n",
    "    def calculate_portfolio_scenarios(self, prices, weights):\n",
    "        \"\"\"\n",
    "        Calculate portfolio value scenarios\n",
    "        \"\"\"\n",
    "        if prices.ndim == 3:  # Multi-asset\n",
    "            portfolio_values = np.sum(prices * weights, axis=2)\n",
    "        else:  # Single asset\n",
    "            portfolio_values = prices * weights\n",
    "        \n",
    "        return portfolio_values\n",
    "    \n",
    "    def calculate_scenario_statistics(self, scenarios):\n",
    "        \"\"\"\n",
    "        Calculate statistics from simulation scenarios\n",
    "        \"\"\"\n",
    "        final_values = scenarios[:, -1]\n",
    "        \n",
    "        stats = {\n",
    "            'mean': np.mean(final_values),\n",
    "            'median': np.median(final_values),\n",
    "            'std': np.std(final_values),\n",
    "            'min': np.min(final_values),\n",
    "            'max': np.max(final_values),\n",
    "            'var_95': np.percentile(final_values, 5),\n",
    "            'var_99': np.percentile(final_values, 1),\n",
    "            'cvar_95': np.mean(final_values[final_values <= np.percentile(final_values, 5)]),\n",
    "            'cvar_99': np.mean(final_values[final_values <= np.percentile(final_values, 1)])\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Run Monte Carlo simulation\n",
    "print(f\"üé≤ Running Monte Carlo simulation with {n_simulations:,} scenarios...\")\n",
    "\n",
    "# Simulation parameters\n",
    "initial_portfolio_value = 100000  # $100K portfolio\n",
    "time_horizon_days = 30  # 30 days\n",
    "\n",
    "# Calculate expected returns and volatilities from historical data\n",
    "expected_returns = returns_data.mean().values * 252  # Annualized\n",
    "volatilities = returns_data.std().values * np.sqrt(252)  # Annualized\n",
    "correlation_matrix = returns_data.corr().values\n",
    "\n",
    "# Equal-weighted portfolio\n",
    "n_assets = len(returns_data.columns)\n",
    "weights = np.ones(n_assets) / n_assets\n",
    "initial_prices = np.ones(n_assets) * (initial_portfolio_value / n_assets)\n",
    "\n",
    "# Run simulation\n",
    "simulator = MonteCarloRiskSimulator(n_simulations=n_simulations, time_horizon=time_horizon_days)\n",
    "price_scenarios = simulator.geometric_brownian_motion(\n",
    "    S0=initial_prices,\n",
    "    mu=expected_returns,\n",
    "    sigma=volatilities,\n",
    "    corr_matrix=correlation_matrix\n",
    ")\n",
    "\n",
    "# Calculate portfolio scenarios\n",
    "portfolio_scenarios = simulator.calculate_portfolio_scenarios(price_scenarios, weights)\n",
    "\n",
    "# Calculate statistics\n",
    "scenario_stats = simulator.calculate_scenario_statistics(portfolio_scenarios)\n",
    "\n",
    "print(\"‚úÖ Monte Carlo simulation complete\")\n",
    "print(f\"üìä Simulation results for {time_horizon_days}-day horizon:\")\n",
    "print(f\"  Expected Portfolio Value: ${scenario_stats['mean']:,.2f}\")\n",
    "print(f\"  95% VaR: ${initial_portfolio_value - scenario_stats['var_95']:,.2f}\")\n",
    "print(f\"  99% VaR: ${initial_portfolio_value - scenario_stats['var_99']:,.2f}\")\n",
    "print(f\"  95% CVaR: ${initial_portfolio_value - scenario_stats['cvar_95']:,.2f}\")\n",
    "print(f\"  Worst Case: ${scenario_stats['min']:,.2f}\")\n",
    "print(f\"  Best Case: ${scenario_stats['max']:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fb5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Monte Carlo results\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['Portfolio Value Scenarios', 'Final Value Distribution', \n",
    "                   'Risk Metrics Comparison', 'Percentile Analysis'],\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"type\": \"bar\"}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# 1. Portfolio scenarios (show subset for clarity)\n",
    "days = np.arange(portfolio_scenarios.shape[1])\n",
    "n_paths_to_show = min(100, n_simulations)\n",
    "\n",
    "for i in range(n_paths_to_show):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=days, y=portfolio_scenarios[i], \n",
    "                  mode='lines', line=dict(width=0.5, color='lightblue'),\n",
    "                  showlegend=False),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Add percentile bands\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "colors = ['red', 'orange', 'green', 'orange', 'red']\n",
    "for i, p in enumerate(percentiles):\n",
    "    values = np.percentile(portfolio_scenarios, p, axis=0)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=days, y=values, mode='lines',\n",
    "                  name=f'{p}th percentile', line=dict(color=colors[i], width=2)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# 2. Final value distribution\n",
    "final_values = portfolio_scenarios[:, -1]\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=final_values, nbinsx=50, name='Final Values',\n",
    "                opacity=0.7, marker_color='skyblue'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Add VaR lines\n",
    "fig.add_vline(x=scenario_stats['var_95'], line_dash=\"dash\", \n",
    "              line_color=\"red\", annotation_text=\"95% VaR\",\n",
    "              row=1, col=2)\n",
    "fig.add_vline(x=scenario_stats['var_99'], line_dash=\"dash\", \n",
    "              line_color=\"darkred\", annotation_text=\"99% VaR\",\n",
    "              row=1, col=2)\n",
    "\n",
    "# 3. Risk metrics comparison\n",
    "risk_metrics_values = [\n",
    "    initial_portfolio_value - scenario_stats['var_95'],\n",
    "    initial_portfolio_value - scenario_stats['var_99'],\n",
    "    initial_portfolio_value - scenario_stats['cvar_95'],\n",
    "    initial_portfolio_value - scenario_stats['cvar_99']\n",
    "]\n",
    "risk_labels = ['VaR 95%', 'VaR 99%', 'CVaR 95%', 'CVaR 99%']\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=risk_labels, y=risk_metrics_values,\n",
    "           marker_color=['lightcoral', 'red', 'orange', 'darkred'],\n",
    "           name='Risk Metrics'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Percentile analysis\n",
    "percentile_range = np.arange(1, 100)\n",
    "percentile_values = [np.percentile(final_values, p) for p in percentile_range]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=percentile_range, y=percentile_values,\n",
    "               mode='lines', name='Percentiles', line=dict(color='purple')),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'üé≤ Monte Carlo Risk Analysis ({n_simulations:,} simulations, {time_horizon_days} days)',\n",
    "    height=800,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Update axis labels\n",
    "fig.update_xaxes(title_text=\"Days\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Portfolio Value ($)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Portfolio Value ($)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Risk Amount ($)\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Percentile\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Portfolio Value ($)\", row=2, col=2)\n",
    "\n",
    "fig.show()\n",
    "print(\"üìä Monte Carlo visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb59c80",
   "metadata": {},
   "source": [
    "## 4. Stress Testing\n",
    "\n",
    "Analyze portfolio performance under extreme market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea191120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress Testing Scenarios\n",
    "class StressTestingFramework:\n",
    "    def __init__(self):\n",
    "        self.scenarios = {}\n",
    "    \n",
    "    def add_scenario(self, name, description, shocks):\n",
    "        \"\"\"\n",
    "        Add a stress testing scenario\n",
    "        \n",
    "        shocks: dict with asset names as keys and shock multipliers as values\n",
    "        \"\"\"\n",
    "        self.scenarios[name] = {\n",
    "            'description': description,\n",
    "            'shocks': shocks\n",
    "        }\n",
    "    \n",
    "    def run_stress_test(self, current_portfolio_value, weights, asset_names):\n",
    "        \"\"\"\n",
    "        Run stress tests on portfolio\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for scenario_name, scenario in self.scenarios.items():\n",
    "            portfolio_change = 0\n",
    "            \n",
    "            for i, asset in enumerate(asset_names):\n",
    "                if asset in scenario['shocks']:\n",
    "                    asset_value = current_portfolio_value * weights[i]\n",
    "                    shock = scenario['shocks'][asset]\n",
    "                    portfolio_change += asset_value * shock\n",
    "            \n",
    "            new_portfolio_value = current_portfolio_value + portfolio_change\n",
    "            loss_amount = current_portfolio_value - new_portfolio_value\n",
    "            loss_percentage = (loss_amount / current_portfolio_value) * 100\n",
    "            \n",
    "            results[scenario_name] = {\n",
    "                'description': scenario['description'],\n",
    "                'portfolio_value': new_portfolio_value,\n",
    "                'loss_amount': loss_amount,\n",
    "                'loss_percentage': loss_percentage\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Define stress testing scenarios\n",
    "stress_tester = StressTestingFramework()\n",
    "\n",
    "# Historical crisis scenarios\n",
    "stress_tester.add_scenario(\n",
    "    'Market_Crash_2008',\n",
    "    '2008-style financial crisis with severe equity and credit stress',\n",
    "    {'Stock': -0.40, 'Bond': -0.10, 'Commodity': -0.35}\n",
    ")\n",
    "\n",
    "stress_tester.add_scenario(\n",
    "    'COVID_Pandemic',\n",
    "    'COVID-19 pandemic scenario with flight to quality',\n",
    "    {'Stock': -0.30, 'Bond': 0.05, 'Commodity': -0.25}\n",
    ")\n",
    "\n",
    "stress_tester.add_scenario(\n",
    "    'Interest_Rate_Shock',\n",
    "    'Sudden 200bp interest rate increase',\n",
    "    {'Stock': -0.15, 'Bond': -0.20, 'Commodity': -0.10}\n",
    ")\n",
    "\n",
    "stress_tester.add_scenario(\n",
    "    'Inflation_Shock',\n",
    "    'Unexpected inflation surge',\n",
    "    {'Stock': -0.20, 'Bond': -0.25, 'Commodity': 0.15}\n",
    ")\n",
    "\n",
    "stress_tester.add_scenario(\n",
    "    'Geopolitical_Crisis',\n",
    "    'Major geopolitical event affecting global markets',\n",
    "    {'Stock': -0.25, 'Bond': 0.03, 'Commodity': 0.20}\n",
    ")\n",
    "\n",
    "# Run stress tests\n",
    "print(\"‚ö° Running stress testing scenarios...\")\n",
    "\n",
    "stress_results = stress_tester.run_stress_test(\n",
    "    current_portfolio_value=initial_portfolio_value,\n",
    "    weights=weights,\n",
    "    asset_names=list(returns_data.columns)\n",
    ")\n",
    "\n",
    "print(\"\\nüí• STRESS TESTING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for scenario, results in stress_results.items():\n",
    "    print(f\"\\nüìä {scenario}:\")\n",
    "    print(f\"   Description: {results['description']}\")\n",
    "    print(f\"   Portfolio Value: ${results['portfolio_value']:,.2f}\")\n",
    "    print(f\"   Loss Amount: ${results['loss_amount']:,.2f}\")\n",
    "    print(f\"   Loss Percentage: {results['loss_percentage']:.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Stress testing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8201d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stress testing results\n",
    "scenario_names = list(stress_results.keys())\n",
    "loss_amounts = [stress_results[s]['loss_amount'] for s in scenario_names]\n",
    "loss_percentages = [stress_results[s]['loss_percentage'] for s in scenario_names]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['Stress Test Losses (Dollar Amount)', 'Stress Test Losses (Percentage)'],\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "# Dollar losses\n",
    "fig.add_trace(\n",
    "    go.Bar(x=scenario_names, y=loss_amounts,\n",
    "           marker_color='red', opacity=0.7,\n",
    "           name='Loss Amount ($)',\n",
    "           text=[f'${x:,.0f}' for x in loss_amounts],\n",
    "           textposition='auto'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Percentage losses\n",
    "fig.add_trace(\n",
    "    go.Bar(x=scenario_names, y=loss_percentages,\n",
    "           marker_color='darkred', opacity=0.7,\n",
    "           name='Loss Percentage (%)',\n",
    "           text=[f'{x:.1f}%' for x in loss_percentages],\n",
    "           textposition='auto'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='üí• Stress Testing Results',\n",
    "    height=500,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_yaxes(title_text=\"Loss Amount ($)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Loss Percentage (%)\", row=1, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Identify worst-case scenario\n",
    "worst_scenario = max(stress_results.keys(), key=lambda x: stress_results[x]['loss_percentage'])\n",
    "worst_loss = stress_results[worst_scenario]['loss_percentage']\n",
    "\n",
    "print(f\"üö® Worst-case scenario: {worst_scenario} ({worst_loss:.2f}% loss)\")\n",
    "print(\"üìä Stress testing visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be2ae9",
   "metadata": {},
   "source": [
    "## 5. Risk Summary and Recommendations\n",
    "\n",
    "Comprehensive summary of risk analysis findings and actionable recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edfef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive risk summary\n",
    "print(\"üéØ COMPREHENSIVE RISK ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä PORTFOLIO OVERVIEW:\")\n",
    "print(f\"   Initial Value: ${initial_portfolio_value:,}\")\n",
    "print(f\"   Assets: {', '.join(returns_data.columns)}\")\n",
    "print(f\"   Allocation: {', '.join([f'{w:.1%}' for w in weights])}\")\n",
    "print(f\"   Analysis Period: {returns_data.index[0].strftime('%Y-%m-%d')} to {returns_data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(f\"\\n‚ö° RISK METRICS ({var_confidence*100}% confidence):\")\n",
    "print(f\"   Monte Carlo VaR (30-day): ${initial_portfolio_value - scenario_stats['var_95']:,.2f}\")\n",
    "print(f\"   Monte Carlo CVaR (30-day): ${initial_portfolio_value - scenario_stats['cvar_95']:,.2f}\")\n",
    "print(f\"   Expected Portfolio Value: ${scenario_stats['mean']:,.2f}\")\n",
    "print(f\"   Volatility Range: ${scenario_stats['min']:,.2f} - ${scenario_stats['max']:,.2f}\")\n",
    "\n",
    "print(f\"\\nüí• STRESS TESTING INSIGHTS:\")\n",
    "worst_scenario_details = stress_results[worst_scenario]\n",
    "print(f\"   Worst-case scenario: {worst_scenario}\")\n",
    "print(f\"   Maximum potential loss: ${worst_scenario_details['loss_amount']:,.2f} ({worst_scenario_details['loss_percentage']:.2f}%)\")\n",
    "print(f\"   Average stress loss: {np.mean(loss_percentages):.2f}%\")\n",
    "\n",
    "print(f\"\\nüìà INDIVIDUAL ASSET RISKS:\")\n",
    "for asset in returns_data.columns:\n",
    "    vol = risk_df.loc[asset, 'Volatility']\n",
    "    sharpe = risk_df.loc[asset, 'Sharpe_Ratio']\n",
    "    var_hist = risk_df.loc[asset, 'Historical_VaR']\n",
    "    print(f\"   {asset}: Vol={vol:.1f}%, Sharpe={sharpe:.3f}, VaR={var_hist:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° RISK MANAGEMENT RECOMMENDATIONS:\")\n",
    "print(\"   1. üõ°Ô∏è  Consider reducing allocation to highest volatility assets\")\n",
    "print(\"   2. üìä  Implement regular VaR monitoring and backtesting\")\n",
    "print(\"   3. üéØ  Establish stop-loss levels based on stress test results\")\n",
    "print(\"   4. üîÑ  Rebalance portfolio quarterly to maintain target allocation\")\n",
    "print(\"   5. üìà  Consider hedging strategies for tail risk protection\")\n",
    "print(\"   6. üîç  Monitor correlation changes during market stress\")\n",
    "\n",
    "print(f\"\\nüìã RISK LIMITS SUGGESTIONS:\")\n",
    "print(f\"   Daily VaR Limit: ${(initial_portfolio_value - scenario_stats['var_95'])/30:.0f} (1-day equivalent)\")\n",
    "print(f\"   Monthly VaR Limit: ${initial_portfolio_value - scenario_stats['var_95']:,.0f}\")\n",
    "print(f\"   Stress Test Threshold: {worst_loss * 0.8:.1f}% (80% of worst case)\")\n",
    "print(f\"   Maximum Single Asset Weight: 40% (diversification)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Risk analysis complete! Regular monitoring and updates recommended.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
