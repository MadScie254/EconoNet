{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Liquidity Modeling with Actual CBK Data\n",
    "# 🏛️ NERVA DIVINE LIQUIDITY INTELLIGENCE - INTERBANK ANALYSIS\n",
    "# Using actual Central Bank of Kenya interbank and repo market data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🏛️ NERVA DIVINE LIQUIDITY MODELING SYSTEM\")\n",
    "print(\"=\"*60)\n",
    "print(\"💰 Initializing Real CBK Liquidity Analysis...\")\n",
    "print(\"🔄 Loading actual interbank market data...\")\n",
    "\n",
    "class RealLiquidityModeler:\n",
    "    \"\"\"Advanced liquidity modeling using real CBK interbank data\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path=\"../data/raw/\"):\n",
    "        self.data_path = data_path\n",
    "        self.interbank_data = None\n",
    "        self.repo_data = None\n",
    "        self.discount_window_data = None\n",
    "        self.horizontal_repo_data = None\n",
    "        self.treasury_bills_data = None\n",
    "        self.treasury_bonds_data = None\n",
    "        \n",
    "    def load_real_liquidity_data(self):\n",
    "        \"\"\"Load all liquidity-related datasets\"\"\"\n",
    "        try:\n",
    "            print(\"\\\\n📥 Loading CBK liquidity datasets...\")\n",
    "            \n",
    "            # Interbank rates and volumes\n",
    "            try:\n",
    "                self.interbank_data = pd.read_csv(f\"{self.data_path}Interbank Rates  Volumes.csv\")\n",
    "                print(f\"   ✅ Interbank Data: {len(self.interbank_data)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️ Primary interbank data not found, trying alternative...\")\n",
    "                try:\n",
    "                    self.interbank_data = pd.read_csv(f\"{self.data_path}Interbank Rates () .csv\")\n",
    "                    print(f\"   ✅ Alternative Interbank Data: {len(self.interbank_data)} records\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"   ❌ Interbank Data error: {str(e2)}\")\n",
    "            \n",
    "            # Repo market operations\n",
    "            try:\n",
    "                self.repo_data = pd.read_csv(f\"{self.data_path}Repo and Reverse Repo .csv\")\n",
    "                print(f\"   ✅ Repo Data: {len(self.repo_data)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Repo Data error: {str(e)}\")\n",
    "            \n",
    "            # Horizontal repo market\n",
    "            try:\n",
    "                self.horizontal_repo_data = pd.read_csv(f\"{self.data_path}Horizontal Repo Market.csv\")\n",
    "                print(f\"   ✅ Horizontal Repo Data: {len(self.horizontal_repo_data)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Horizontal Repo Data error: {str(e)}\")\n",
    "            \n",
    "            # Discount window operations\n",
    "            try:\n",
    "                self.discount_window_data = pd.read_csv(f\"{self.data_path}Discount Window.csv\")\n",
    "                print(f\"   ✅ Discount Window Data: {len(self.discount_window_data)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Discount Window Data error: {str(e)}\")\n",
    "            \n",
    "            # Treasury bills (liquidity management tool)\n",
    "            try:\n",
    "                self.treasury_bills_data = pd.read_csv(f\"{self.data_path}Issues of Treasury Bills.csv\")\n",
    "                print(f\"   ✅ Treasury Bills Data: {len(self.treasury_bills_data)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Treasury Bills Data error: {str(e)}\")\n",
    "            \n",
    "            # Treasury bonds\n",
    "            try:\n",
    "                self.treasury_bonds_data = pd.read_csv(f\"{self.data_path}Issues of Treasury Bonds.csv\")\n",
    "                print(f\"   ✅ Treasury Bonds Data: {len(self.treasury_bonds_data)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Treasury Bonds Data error: {str(e)}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading liquidity data: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def preprocess_interbank_data(self):\n",
    "        \"\"\"Process interbank market data for liquidity analysis\"\"\"\n",
    "        if self.interbank_data is None:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            df = self.interbank_data.copy()\n",
    "            \n",
    "            # Display first few rows to understand structure\n",
    "            print(\"\\\\n📊 Interbank data structure:\")\n",
    "            print(df.head())\n",
    "            print(f\"Columns: {list(df.columns)}\")\n",
    "            \n",
    "            # Find date and rate columns\n",
    "            date_cols = [col for col in df.columns if any(word in col.lower() for word in ['date', 'period', 'time'])]\n",
    "            rate_cols = [col for col in df.columns if any(word in col.lower() for word in ['rate', 'interbank', 'overnight'])]\n",
    "            volume_cols = [col for col in df.columns if any(word in col.lower() for word in ['volume', 'amount', 'value'])]\n",
    "            \n",
    "            if date_cols:\n",
    "                # Process with identified columns\n",
    "                df_clean = df.copy()\n",
    "                \n",
    "                # Clean date column\n",
    "                date_col = date_cols[0]\n",
    "                df_clean['date'] = pd.to_datetime(df_clean[date_col], errors='coerce')\n",
    "                df_clean = df_clean.dropna(subset=['date'])\n",
    "                \n",
    "                # Process rate columns\n",
    "                if rate_cols:\n",
    "                    for rate_col in rate_cols[:3]:  # Take first 3 rate columns\n",
    "                        df_clean[f'rate_{rate_col}'] = pd.to_numeric(df_clean[rate_col], errors='coerce')\n",
    "                \n",
    "                # Process volume columns\n",
    "                if volume_cols:\n",
    "                    for vol_col in volume_cols[:3]:  # Take first 3 volume columns\n",
    "                        df_clean[f'volume_{vol_col}'] = pd.to_numeric(df_clean[vol_col], errors='coerce')\n",
    "                \n",
    "                # Sort by date\n",
    "                df_clean = df_clean.sort_values('date').reset_index(drop=True)\n",
    "                \n",
    "                # Calculate liquidity metrics\n",
    "                if rate_cols:\n",
    "                    main_rate_col = f'rate_{rate_cols[0]}'\n",
    "                    if main_rate_col in df_clean.columns:\n",
    "                        df_clean['rate_volatility'] = df_clean[main_rate_col].rolling(window=5).std()\n",
    "                        df_clean['rate_trend'] = df_clean[main_rate_col].rolling(window=5).mean()\n",
    "                \n",
    "                print(f\"✅ Interbank data processed: {len(df_clean)} records\")\n",
    "                return df_clean\n",
    "            else:\n",
    "                print(\"❌ Could not identify date columns in interbank data\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing interbank data: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_liquidity_conditions(self, interbank_df):\n",
    "        \"\"\"Analyze current liquidity conditions\"\"\"\n",
    "        if interbank_df is None:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            # Find rate columns\n",
    "            rate_cols = [col for col in interbank_df.columns if col.startswith('rate_')]\n",
    "            \n",
    "            if not rate_cols:\n",
    "                print(\"❌ No rate columns found for liquidity analysis\")\n",
    "                return None\n",
    "            \n",
    "            main_rate_col = rate_cols[0]\n",
    "            \n",
    "            analysis = {\n",
    "                'current_rate': interbank_df[main_rate_col].iloc[-1] if not pd.isna(interbank_df[main_rate_col].iloc[-1]) else 0,\n",
    "                'avg_rate': interbank_df[main_rate_col].mean(),\n",
    "                'rate_volatility': interbank_df[main_rate_col].std(),\n",
    "                'liquidity_stress': 'High' if interbank_df[main_rate_col].iloc[-1] > interbank_df[main_rate_col].quantile(0.75) else 'Normal',\n",
    "                'recent_trend': 'Tightening' if interbank_df[main_rate_col].iloc[-5:].mean() > interbank_df[main_rate_col].iloc[-10:-5].mean() else 'Easing',\n",
    "                'data_points': len(interbank_df),\n",
    "                'rate_range': f\"{interbank_df[main_rate_col].min():.2f}% - {interbank_df[main_rate_col].max():.2f}%\"\n",
    "            }\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error analyzing liquidity conditions: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def create_liquidity_dashboard(self, interbank_df, repo_df=None):\n",
    "        \"\"\"Create comprehensive liquidity analysis dashboard\"\"\"\n",
    "        if interbank_df is None:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            # Find rate columns\n",
    "            rate_cols = [col for col in interbank_df.columns if col.startswith('rate_')]\n",
    "            volume_cols = [col for col in interbank_df.columns if col.startswith('volume_')]\n",
    "            \n",
    "            if not rate_cols:\n",
    "                print(\"❌ No rate data available for dashboard\")\n",
    "                return None\n",
    "                \n",
    "            main_rate_col = rate_cols[0]\n",
    "            \n",
    "            # Create subplot layout\n",
    "            rows = 2 if repo_df is None else 3\n",
    "            fig = make_subplots(\n",
    "                rows=rows, cols=2,\n",
    "                subplot_titles=(\n",
    "                    'Interbank Rate Evolution',\n",
    "                    'Rate Volatility Analysis',\n",
    "                    'Trading Volume (if available)',\n",
    "                    'Liquidity Stress Indicators'\n",
    "                ) + (('Repo Market Activity', 'Policy Operations') if repo_df is not None else ()),\n",
    "                specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}]] * rows\n",
    "            )\n",
    "            \n",
    "            # Interbank rates\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=interbank_df['date'],\n",
    "                    y=interbank_df[main_rate_col],\n",
    "                    mode='lines+markers',\n",
    "                    name='Interbank Rate',\n",
    "                    line=dict(color='darkblue', width=2),\n",
    "                    marker=dict(size=4)\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # Rate volatility\n",
    "            if 'rate_volatility' in interbank_df.columns:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=interbank_df['date'],\n",
    "                        y=interbank_df['rate_volatility'],\n",
    "                        mode='lines',\n",
    "                        name='Rate Volatility',\n",
    "                        line=dict(color='red', width=2),\n",
    "                        fill='tonexty'\n",
    "                    ),\n",
    "                    row=1, col=2\n",
    "                )\n",
    "            \n",
    "            # Volume analysis (if available)\n",
    "            if volume_cols:\n",
    "                main_vol_col = volume_cols[0]\n",
    "                fig.add_trace(\n",
    "                    go.Bar(\n",
    "                        x=interbank_df['date'],\n",
    "                        y=interbank_df[main_vol_col],\n",
    "                        name='Trading Volume',\n",
    "                        marker_color='lightblue'\n",
    "                    ),\n",
    "                    row=2, col=1\n",
    "                )\n",
    "            \n",
    "            # Liquidity stress heatmap\n",
    "            rate_values = interbank_df[main_rate_col].dropna()\n",
    "            stress_levels = pd.cut(rate_values, bins=5, labels=['Low', 'Moderate', 'Normal', 'Elevated', 'High'])\n",
    "            stress_counts = stress_levels.value_counts()\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=stress_counts.index,\n",
    "                    y=stress_counts.values,\n",
    "                    name='Liquidity Stress Distribution',\n",
    "                    marker_color=['green', 'lightgreen', 'yellow', 'orange', 'red'][:len(stress_counts)]\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=\"💰 REAL CBK LIQUIDITY CONDITIONS ANALYSIS\",\n",
    "                height=600 if repo_df is None else 900,\n",
    "                showlegend=True,\n",
    "                title_font=dict(size=18, color='darkblue')\n",
    "            )\n",
    "            \n",
    "            return fig\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error creating liquidity dashboard: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Initialize the liquidity modeler\n",
    "liquidity_modeler = RealLiquidityModeler()\n",
    "\n",
    "print(\"\\\\n🚀 INITIALIZING REAL LIQUIDITY ANALYSIS...\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Analyze Real Liquidity Data\n",
    "print(\"💰 LOADING REAL CBK LIQUIDITY DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load all liquidity-related datasets\n",
    "data_loaded = liquidity_modeler.load_real_liquidity_data()\n",
    "\n",
    "if data_loaded:\n",
    "    # Process interbank data (main liquidity indicator)\n",
    "    print(\"\\\\n🔧 Processing interbank market data...\")\n",
    "    interbank_processed = liquidity_modeler.preprocess_interbank_data()\n",
    "    \n",
    "    if interbank_processed is not None:\n",
    "        # Analyze liquidity conditions\n",
    "        print(\"\\\\n🔍 Analyzing liquidity conditions...\")\n",
    "        liquidity_analysis = liquidity_modeler.analyze_liquidity_conditions(interbank_processed)\n",
    "        \n",
    "        if liquidity_analysis:\n",
    "            # Display key insights\n",
    "            print(f\"\\\\n🎯 LIQUIDITY MARKET INSIGHTS:\")\n",
    "            print(f\"   💰 Current Interbank Rate: {liquidity_analysis['current_rate']:.2f}%\")\n",
    "            print(f\"   📊 Average Rate: {liquidity_analysis['avg_rate']:.2f}%\")\n",
    "            print(f\"   📈 Market Trend: {liquidity_analysis['recent_trend']}\")\n",
    "            print(f\"   ⚠️ Liquidity Stress: {liquidity_analysis['liquidity_stress']}\")\n",
    "            print(f\"   🎯 Rate Volatility: {liquidity_analysis['rate_volatility']:.2f}%\")\n",
    "            print(f\"   📊 Data Points: {liquidity_analysis['data_points']}\")\n",
    "            print(f\"   📈 Rate Range: {liquidity_analysis['rate_range']}\")\n",
    "            \n",
    "            # Create comprehensive dashboard\n",
    "            print(\"\\\\n📊 Creating liquidity analysis dashboard...\")\n",
    "            liquidity_dashboard = liquidity_modeler.create_liquidity_dashboard(\n",
    "                interbank_processed, \n",
    "                liquidity_modeler.repo_data\n",
    "            )\n",
    "            \n",
    "            if liquidity_dashboard:\n",
    "                liquidity_dashboard.show()\n",
    "                print(\"✅ Liquidity dashboard created successfully!\")\n",
    "            else:\n",
    "                print(\"❌ Failed to create liquidity dashboard\")\n",
    "        else:\n",
    "            print(\"❌ Failed to analyze liquidity conditions\")\n",
    "    else:\n",
    "        print(\"❌ Failed to process interbank data\")\n",
    "else:\n",
    "    print(\"❌ Failed to load liquidity datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2df136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Liquidity Forecasting & Repo Market Analysis\n",
    "print(\"\\\\n🧠 ADVANCED LIQUIDITY FORECASTING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "class LiquidityForecaster:\n",
    "    \"\"\"Advanced liquidity forecasting using CBK market data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "            'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "            'Lasso Regression': Lasso(alpha=0.1, random_state=42),\n",
    "            'Linear Model': LinearRegression()\n",
    "        }\n",
    "        self.scaler = StandardScaler()\n",
    "        self.best_model = None\n",
    "        self.model_performance = {}\n",
    "    \n",
    "    def create_liquidity_features(self, interbank_df):\n",
    "        \"\"\"Create comprehensive features for liquidity forecasting\"\"\"\n",
    "        features_df = interbank_df.copy()\n",
    "        \n",
    "        # Find main rate column\n",
    "        rate_cols = [col for col in features_df.columns if col.startswith('rate_')]\n",
    "        if not rate_cols:\n",
    "            print(\"❌ No rate columns found for feature creation\")\n",
    "            return None\n",
    "            \n",
    "        main_rate_col = rate_cols[0]\n",
    "        \n",
    "        # Lagged rate features\n",
    "        for lag in [1, 2, 3, 5, 10]:\n",
    "            features_df[f'rate_lag_{lag}'] = features_df[main_rate_col].shift(lag)\n",
    "        \n",
    "        # Rolling statistics\n",
    "        for window in [3, 5, 10, 20]:\n",
    "            features_df[f'rate_ma_{window}'] = features_df[main_rate_col].rolling(window=window).mean()\n",
    "            features_df[f'rate_std_{window}'] = features_df[main_rate_col].rolling(window=window).std()\n",
    "        \n",
    "        # Rate change features\n",
    "        features_df['rate_change_1'] = features_df[main_rate_col].diff(1)\n",
    "        features_df['rate_change_5'] = features_df[main_rate_col].diff(5)\n",
    "        \n",
    "        # Momentum indicators\n",
    "        features_df['rate_momentum_3'] = features_df[main_rate_col].rolling(3).apply(lambda x: x.iloc[-1] - x.iloc[0])\n",
    "        features_df['rate_momentum_5'] = features_df[main_rate_col].rolling(5).apply(lambda x: x.iloc[-1] - x.iloc[0])\n",
    "        \n",
    "        # Volatility indicators\n",
    "        features_df['rate_volatility_5'] = features_df[main_rate_col].rolling(5).std()\n",
    "        features_df['rate_volatility_10'] = features_df[main_rate_col].rolling(10).std()\n",
    "        \n",
    "        # Market stress indicators\n",
    "        features_df['rate_above_median'] = (features_df[main_rate_col] > features_df[main_rate_col].rolling(20).median()).astype(int)\n",
    "        features_df['high_volatility'] = (features_df['rate_volatility_5'] > features_df['rate_volatility_5'].rolling(20).mean()).astype(int)\n",
    "        \n",
    "        # Time-based features\n",
    "        features_df['month'] = features_df['date'].dt.month\n",
    "        features_df['quarter'] = features_df['date'].dt.quarter\n",
    "        features_df['day_of_week'] = features_df['date'].dt.dayofweek\n",
    "        \n",
    "        return features_df.dropna()\n",
    "    \n",
    "    def prepare_liquidity_forecasting_data(self, features_df, forecast_horizon=5):\n",
    "        \"\"\"Prepare data for liquidity forecasting\"\"\"\n",
    "        # Find main rate column\n",
    "        rate_cols = [col for col in features_df.columns if col.startswith('rate_') and not any(x in col for x in ['lag', 'ma', 'std', 'change', 'momentum', 'volatility'])]\n",
    "        \n",
    "        if not rate_cols:\n",
    "            print(\"❌ No main rate column found\")\n",
    "            return None, None, None\n",
    "            \n",
    "        main_rate_col = rate_cols[0]\n",
    "        \n",
    "        # Create future target\n",
    "        features_df[f'future_rate_{forecast_horizon}'] = features_df[main_rate_col].shift(-forecast_horizon)\n",
    "        \n",
    "        # Remove rows with NaN targets\n",
    "        df_clean = features_df.dropna()\n",
    "        \n",
    "        # Select feature columns\n",
    "        feature_cols = [col for col in df_clean.columns if col not in ['date', main_rate_col, f'future_rate_{forecast_horizon}']]\n",
    "        \n",
    "        X = df_clean[feature_cols]\n",
    "        y = df_clean[f'future_rate_{forecast_horizon}']\n",
    "        \n",
    "        return X, y, feature_cols\n",
    "    \n",
    "    def train_liquidity_models(self, X, y):\n",
    "        \"\"\"Train liquidity forecasting models\"\"\"\n",
    "        # Split data for validation\n",
    "        split_idx = int(len(X) * 0.8)\n",
    "        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\\\n🤖 Training {name} for liquidity forecasting...\")\n",
    "            \n",
    "            # Scale features\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_test_scaled = self.scaler.transform(X_test)\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Predict\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'mae': mae,\n",
    "                'mse': mse,\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'predictions': y_pred,\n",
    "                'actual': y_test\n",
    "            }\n",
    "            \n",
    "            print(f\"   📊 MAE: {mae:.4f}\")\n",
    "            print(f\"   📊 RMSE: {rmse:.4f}\")\n",
    "            print(f\"   📊 R²: {r2:.4f}\")\n",
    "        \n",
    "        # Find best model\n",
    "        best_model_name = max(results.keys(), key=lambda x: results[x]['r2'])\n",
    "        self.best_model = results[best_model_name]['model']\n",
    "        self.model_performance = results\n",
    "        \n",
    "        print(f\"\\\\n🏆 Best Model: {best_model_name} (R²: {results[best_model_name]['r2']:.4f})\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def create_forecasting_visualization(self, model_results):\n",
    "        \"\"\"Create liquidity forecasting visualization\"\"\"\n",
    "        try:\n",
    "            fig = make_subplots(\n",
    "                rows=2, cols=2,\n",
    "                subplot_titles=(\n",
    "                    'Model Performance Comparison',\n",
    "                    'Best Model: Predicted vs Actual',\n",
    "                    'Forecasting Accuracy',\n",
    "                    'Model Residuals'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Model performance comparison\n",
    "            models = list(model_results.keys())\n",
    "            r2_scores = [model_results[model]['r2'] for model in models]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(name='R² Score', x=models, y=r2_scores, marker_color='lightblue'),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # Best model predictions\n",
    "            best_model_name = max(models, key=lambda x: model_results[x]['r2'])\n",
    "            best_results = model_results[best_model_name]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(name='Actual', y=best_results['actual'].values, mode='lines', line=dict(color='blue')),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(name='Predicted', y=best_results['predictions'], mode='lines', line=dict(color='red')),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            \n",
    "            # RMSE comparison\n",
    "            rmse_scores = [model_results[model]['rmse'] for model in models]\n",
    "            fig.add_trace(\n",
    "                go.Bar(name='RMSE', x=models, y=rmse_scores, marker_color='lightcoral'),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "            # Residuals\n",
    "            residuals = best_results['actual'].values - best_results['predictions']\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=best_results['predictions'], y=residuals, mode='markers', \n",
    "                          name='Residuals', marker=dict(color='green')),\n",
    "                row=2, col=2\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=\"💰 LIQUIDITY FORECASTING MODEL PERFORMANCE\",\n",
    "                height=800,\n",
    "                showlegend=True\n",
    "            )\n",
    "            \n",
    "            return fig\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error creating forecasting visualization: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Initialize forecaster and run analysis\n",
    "forecaster = LiquidityForecaster()\n",
    "\n",
    "if 'interbank_processed' in locals() and interbank_processed is not None:\n",
    "    print(\"\\\\n🔧 Creating liquidity forecasting features...\")\n",
    "    liquidity_features = forecaster.create_liquidity_features(interbank_processed)\n",
    "    \n",
    "    if liquidity_features is not None:\n",
    "        print(f\"   📊 Features created: {len(liquidity_features.columns)}\")\n",
    "        print(f\"   📊 Sample size: {len(liquidity_features)}\")\n",
    "        \n",
    "        # Prepare forecasting data\n",
    "        print(\"\\\\n🎯 Preparing liquidity forecasting data...\")\n",
    "        X, y, feature_cols = forecaster.prepare_liquidity_forecasting_data(liquidity_features)\n",
    "        \n",
    "        if X is not None and len(X) > 10:  # Need minimum data for training\n",
    "            print(f\"   📊 Training samples: {len(X)}\")\n",
    "            print(f\"   📊 Features: {len(feature_cols)}\")\n",
    "            \n",
    "            # Train forecasting models\n",
    "            print(\"\\\\n🚀 Training liquidity forecasting models...\")\n",
    "            forecast_results = forecaster.train_liquidity_models(X, y)\n",
    "            \n",
    "            # Create visualization\n",
    "            print(\"\\\\n📊 Creating forecasting visualization...\")\n",
    "            forecast_viz = forecaster.create_forecasting_visualization(forecast_results)\n",
    "            \n",
    "            if forecast_viz:\n",
    "                forecast_viz.show()\n",
    "                print(\"✅ Liquidity forecasting analysis complete!\")\n",
    "            \n",
    "            print(f\"\\\\n🎯 LIQUIDITY FORECASTING INSIGHTS:\")\n",
    "            best_model = max(forecast_results.keys(), key=lambda x: forecast_results[x]['r2'])\n",
    "            print(f\"   🏆 Best Model: {best_model}\")\n",
    "            print(f\"   📊 Accuracy (R²): {forecast_results[best_model]['r2']:.4f}\")\n",
    "            print(f\"   🎯 Prediction Error: ±{forecast_results[best_model]['rmse']:.4f}%\")\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ Insufficient data for liquidity forecasting\")\n",
    "    else:\n",
    "        print(\"❌ Failed to create liquidity features\")\n",
    "else:\n",
    "    print(\"❌ No interbank data available for liquidity forecasting\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
