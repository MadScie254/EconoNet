{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c10973",
   "metadata": {},
   "source": [
    "# Advanced Time-Series Forecasting for Economic Indicators\n",
    "\n",
    "## Multivariate Forecasting with ARIMA, Prophet, and VAR Models\n",
    "\n",
    "This notebook demonstrates advanced time-series forecasting techniques to predict key Kenyan economic indicators. We will use the cleaned dataset from the data exploration phase to build and compare several powerful models.\n",
    "\n",
    "### Key Models & Concepts:\n",
    "- **ARIMA**: A robust baseline model for univariate time-series forecasting.\n",
    "- **Prophet**: A powerful forecasting tool from Facebook that excels with seasonality and trend decomposition.\n",
    "- **Vector Autoregression (VAR)**: A multivariate model that captures the linear interdependencies among multiple time series.\n",
    "- **Model Evaluation**: Rigorous comparison of model performance using standard metrics and visualizations.\n",
    "- **Forecasting**: Generating future predictions based on the best-performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3cb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time-series modeling libraries\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from prophet import Prophet\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context('talk')\n",
    "\n",
    "print(\"ðŸ“š Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Cleaned Data ---\n",
    "# This assumes you have run the Data_Exploration.ipynb notebook first\n",
    "# to generate the cleaned and merged dataset.\n",
    "# For simplicity, we will replicate the key data loading and cleaning steps here.\n",
    "\n",
    "data_dir = '../data/raw/'\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Loads, cleans, and merges the key economic datasets.\"\"\"\n",
    "    # Load GDP\n",
    "    gdp = pd.read_csv(f'{data_dir}Annual GDP.csv')\n",
    "    gdp.columns = ['Year', 'Nominal_GDP_Ksh_M', 'Real_GDP_Ksh_M', 'Real_GDP_Growth']\n",
    "    gdp['Year'] = pd.to_datetime(gdp['Year'], format='%Y')\n",
    "    gdp.set_index('Year', inplace=True)\n",
    "    for col in gdp.columns:\n",
    "        gdp[col] = pd.to_numeric(gdp[col].astype(str).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "    # Load Debt\n",
    "    debt = pd.read_csv(f'{data_dir}Public Debt.csv', skiprows=3)\n",
    "    debt = debt.iloc[:, :2]\n",
    "    debt.columns = ['Date', 'Total_Debt_Ksh_B']\n",
    "    debt['Date'] = pd.to_datetime(debt['Date'], errors='coerce')\n",
    "    debt.dropna(subset=['Date'], inplace=True)\n",
    "    debt.set_index('Date', inplace=True)\n",
    "    debt['Total_Debt_Ksh_B'] = pd.to_numeric(debt['Total_Debt_Ksh_B'].astype(str).str.replace(',', ''), errors='coerce')\n",
    "    debt = debt.resample('A').last()\n",
    "\n",
    "    # Load FX\n",
    "    fx = pd.read_csv(f'{data_dir}Monthly exchange rate (end period).csv', skiprows=3)\n",
    "    fx = fx.iloc[:, :2]\n",
    "    fx.columns = ['Date', 'KES_USD']\n",
    "    fx['Date'] = pd.to_datetime(fx['Date'], errors='coerce')\n",
    "    fx.dropna(subset=['Date'], inplace=True)\n",
    "    fx.set_index('Date', inplace=True)\n",
    "    fx['KES_USD'] = pd.to_numeric(fx['KES_USD'].astype(str).str.replace(',', ''), errors='coerce')\n",
    "    fx = fx.resample('A').mean()\n",
    "\n",
    "    # Merge and create features\n",
    "    df = gdp.join(debt, how='inner').join(fx, how='inner')\n",
    "    df['Debt_to_GDP_Ratio'] = (df['Total_Debt_Ksh_B'] * 1000) / df['Nominal_GDP_Ksh_M']\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_and_prepare_data()\n",
    "target_variable = 'Real_GDP_Growth'\n",
    "exog_variables = ['Total_Debt_Ksh_B', 'KES_USD', 'Debt_to_GDP_Ratio']\n",
    "\n",
    "print(\"ðŸ“Š Loaded and prepared data for modeling.\")\n",
    "print(f\"Target Variable: {target_variable}\")\n",
    "print(f\"Exogenous Variables: {exog_variables}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67559f7e",
   "metadata": {},
   "source": [
    "## 1. Data Generation and Preparation\n",
    "\n",
    "We'll create synthetic economic data that mimics real-world patterns:\n",
    "- Long-term trend\n",
    "- Seasonal patterns\n",
    "- Economic cycles\n",
    "- Random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df[0:train_size], df[train_size:len(df)]\n",
    "\n",
    "print(f\"Training set size: {len(train)}\")\n",
    "print(f\"Test set size: {len(test)}\")\n",
    "\n",
    "# Fit the ARIMA model\n",
    "# Note: ARIMA parameters (p,d,q) should be determined through rigorous analysis (e.g., ACF/PACF plots)\n",
    "# For this example, we use common starting values.\n",
    "arima_model = ARIMA(train[target_variable], order=(1, 1, 1)).fit()\n",
    "print(\"\\nðŸ“Š ARIMA Model Summary\")\n",
    "print(arima_model.summary())\n",
    "\n",
    "# Make predictions\n",
    "arima_preds = arima_model.forecast(steps=len(test))\n",
    "arima_rmse = np.sqrt(mean_squared_error(test[target_variable], arima_preds))\n",
    "print(f\"\\nARIMA Test RMSE: {arima_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA forecast vs actuals\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train.index, y=train[target_variable], mode='lines', name='Training Data'))\n",
    "fig.add_trace(go.Scatter(x=test.index, y=test[target_variable], mode='lines', name='Test Data (Actuals)'))\n",
    "fig.add_trace(go.Scatter(x=test.index, y=arima_preds, mode='lines', name='ARIMA Forecast', line=dict(dash='dash')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'ARIMA Forecast for {target_variable}',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title=target_variable,\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b0ca90",
   "metadata": {},
   "source": [
    "## 3. Advanced Forecasting with Prophet\n",
    "\n",
    "Prophet is a forecasting tool developed by Facebook that is robust to missing data and shifts in trend, and typically handles seasonality well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0026d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Prophet\n",
    "prophet_train_df = train.reset_index().rename(columns={'Year': 'ds', target_variable: 'y'})\n",
    "\n",
    "# Initialize and fit the model\n",
    "prophet_model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "prophet_model.fit(prophet_train_df)\n",
    "\n",
    "# Create future dataframe\n",
    "future = prophet_model.make_future_dataframe(periods=len(test), freq='A')\n",
    "prophet_forecast = prophet_model.predict(future)\n",
    "\n",
    "# Extract predictions and calculate RMSE\n",
    "prophet_preds = prophet_forecast['yhat'][-len(test):]\n",
    "prophet_rmse = np.sqrt(mean_squared_error(test[target_variable], prophet_preds))\n",
    "print(f\"Prophet Test RMSE: {prophet_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c78c21f",
   "metadata": {},
   "source": [
    "## 4. Multivariate Forecasting with Vector Autoregression (VAR)\n",
    "\n",
    "The VAR model captures the linear interdependencies among multiple time series. It's a powerful tool for multivariate forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecef092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stationarity (required for VAR)\n",
    "def check_stationarity(df):\n",
    "    \"\"\"Perform ADF test for stationarity.\"\"\"\n",
    "    results = {}\n",
    "    for col in df.columns:\n",
    "        adf_test = adfuller(df[col])\n",
    "        results[col] = {'ADF Statistic': adf_test[0], 'p-value': adf_test[1]}\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Stationarity Check (p-values):\")\n",
    "# We use diff() to make the series stationary if needed\n",
    "stationarity_results = check_stationarity(train[[target_variable] + exog_variables].diff().dropna())\n",
    "print(stationarity_results.loc['p-value'])\n",
    "\n",
    "# Fit the VAR model on differenced data\n",
    "var_data = train[[target_variable] + exog_variables].diff().dropna()\n",
    "var_model = VARMAX(var_data, order=(1, 0)).fit(disp=False)\n",
    "print(\"\\nðŸ“Š VAR Model Summary\")\n",
    "print(var_model.summary())\n",
    "\n",
    "# Forecast\n",
    "var_forecast = var_model.forecast(steps=len(test))\n",
    "var_preds = var_forecast[target_variable]\n",
    "\n",
    "# Invert the differencing\n",
    "var_preds_inversed = train[target_variable].iloc[-1] + var_preds.cumsum()\n",
    "var_rmse = np.sqrt(mean_squared_error(test[target_variable], var_preds_inversed))\n",
    "print(f\"\\nVAR Test RMSE for {target_variable}: {var_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prophet forecast components\n",
    "fig = prophet_model.plot_components(prophet_forecast)\n",
    "plt.suptitle(f'Prophet Model Components for {target_variable}', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VAR forecast vs actuals\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train.index, y=train[target_variable], mode='lines', name='Training Data'))\n",
    "fig.add_trace(go.Scatter(x=test.index, y=test[target_variable], mode='lines', name='Test Data (Actuals)'))\n",
    "fig.add_trace(go.Scatter(x=test.index, y=var_preds_inversed, mode='lines', name='VAR Forecast', line=dict(dash='dash')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'VAR Forecast for {target_variable}',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title=target_variable,\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad59146",
   "metadata": {},
   "source": [
    "## 5. Comprehensive Model Comparison\n",
    "\n",
    "Let's compare the performance of all our models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': test[target_variable],\n",
    "    'ARIMA': arima_preds,\n",
    "    'Prophet': prophet_preds.values,\n",
    "    'VAR': var_preds_inversed.values\n",
    "}, index=test.index)\n",
    "\n",
    "# Plot all forecasts\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df[target_variable], mode='lines', name='Historical Data'))\n",
    "fig.add_trace(go.Scatter(x=comparison_df.index, y=comparison_df['Actual'], mode='lines+markers', name='Actual Test Data'))\n",
    "fig.add_trace(go.Scatter(x=comparison_df.index, y=comparison_df['ARIMA'], mode='lines', name='ARIMA Forecast', line=dict(dash='dot')))\n",
    "fig.add_trace(go.Scatter(x=comparison_df.index, y=comparison_df['Prophet'], mode='lines', name='Prophet Forecast', line=dict(dash='dashdot')))\n",
    "fig.add_trace(go.Scatter(x=comparison_df.index, y=comparison_df['VAR'], mode='lines', name='VAR Forecast', line=dict(dash='dash')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Model Comparison for {target_variable} Forecasting',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title=target_variable,\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display RMSE scores\n",
    "rmse_scores = {\n",
    "    'ARIMA': arima_rmse,\n",
    "    'Prophet': prophet_rmse,\n",
    "    'VAR': var_rmse\n",
    "}\n",
    "rmse_df = pd.DataFrame(rmse_scores, index=['RMSE']).T.sort_values('RMSE')\n",
    "\n",
    "print(\"ðŸ“Š MODEL PERFORMANCE (RMSE)\")\n",
    "print(\"=\"*30)\n",
    "print(rmse_df)\n",
    "\n",
    "print(\"\\nðŸŽ¯ CONCLUSION:\")\n",
    "print(f\"The best performing model based on RMSE is **{rmse_df.index[0]}**.\")\n",
    "print(\"This comprehensive analysis demonstrates how different advanced models can be applied to forecast complex economic indicators.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86164285",
   "metadata": {},
   "source": [
    "## 5. Summary and Insights\n",
    "\n",
    "Key findings from the predictive modeling analysis."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
